---
title: "EDA"
author: "Melissa Eckert, Robert Feldstein, Yue Li, Haonan Chen"
date: "`r Sys.Date()`"
output: pdf_document
---
# Exploratory Data Analysis

Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(openxlsx)
library(dplyr)
library(ggplot2)
library(tidyr)
```

Load data 
```{r}
df <- read.xlsx("Data/FinalDataSet.xlsx", sheet = 1)
```

# Data Summary

```{r}
summary(df)
```

## Repetition of Python Work

```{r}

# Make a dataset that is just the first core attributes 
core_scores <- c("UniqueID", "strBlock", "service", "medical", "clinical_reasoning", "professionalism", "collaboration")
core_df <- df[, core_scores]

# Remove rows with missing values
core_df <- core_df %>% na.omit()

# Group by strBlock to get the mean of each core attribute at each rotation
core_df_grouped <- core_df %>% group_by(strBlock) %>% summarise_all(mean)
core_df_grouped <- core_df_grouped %>% select(-UniqueID) %>% select(-service)

# Plot the mean scores over the strBlocks

core_df_grouped_long <- gather(core_df_grouped, key = "Attribute", value = "Score", -strBlock)

ggplot(core_df_grouped_long, aes(x = strBlock, y = Score, color = Attribute)) + geom_line() + geom_point() + labs(title = "Mean Scores of Core Attributes Over Time", x = "Rotation", y = "Mean Score") + theme_minimal()





```


```{r}
# Select all the rows that have missing values
df_missing <- df %>% filter(is.na(medical) | is.na(clinical_reasoning) | is.na(professionalism) | is.na(collaboration))
df_missing
# Why does service 6615 only have service_specific?
# Not even the core categories are completely filled.
```

```{r}
# Get counts of the number of times each column is not missing
df %>% summarise_all(~sum(!is.na(.)))
```

As we can see, certain score categories have significantly more data than others.


```{r}
# Make correlation matrix

core_df_cor <- core_df %>% select(-UniqueID) %>% select(-strBlock)  %>% select(-service)
core_df_cor <- cor(core_df_cor)

# Make into heatmap
ggplot(data = as.data.frame(as.table(core_df_cor)), aes(Var1, Var2, fill = Freq)) + geom_tile() + scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) + theme_minimal() + labs(title = "Correlation Matrix of Core Attributes", x = "Attribute", y = "Attribute", fill = "Correlation") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
# Make some violin plots of the core attributes with the other attributes 

# predictive variables (these are binary)
non_score_vars <- c("Hosp", "Early", "PIPActive", "PIPYN")
score_categories <- c("medical", "clinical_reasoning", "professionalism", "collaboration")

boxplot <- function(df, x, y) {
  df_filtered <- df %>%
    filter(!is.na(.data[[x]]), !is.na(.data[[y]])) %>%
    mutate(!!x := as.factor(.data[[x]]))
  
  p <- ggplot(df_filtered, aes(x = .data[[x]], y = .data[[y]], fill = .data[[x]])) +
    geom_boxplot(outlier.shape = 21, outlier.fill = "white", outlier.size = 2, width = 0.6) + 
    stat_summary(fun = mean, geom = "point", shape = 23, size = 3, fill = "red") +  # Mean as red diamond
    scale_fill_brewer(palette = "Set2") +  # Use a distinct color palette
    ggtitle(paste("Boxplot of", y, "by", x)) +
    xlab(x) +
    ylab(y) +
    theme_minimal(base_size = 14) +
    theme(legend.position = "none", 
          axis.text.x = element_text(angle = 45, hjust = 1),
          plot.title = element_text(face = "bold", hjust = 0.5))
  
  print(p)
}

for (var in non_score_vars) {
  for (cat in score_categories) {
    boxplot(df, var, cat)
  }
}


```

## Is the data normally distributed?

```{r}

# Histogram of the core_scores 

core_vals <- c("medical", "clinical_reasoning", "professionalism", "collaboration")


for (val in core_vals) {
  hist(df[[val]], main = paste("Histogram of", val), xlab = val)
}


```

Obviously collaboration and professionalism are not normally distributed, they are basically just straight line increases where the vast majority of students are scoring well in both categories across all of the rotations. It may be a good idea to consider re-evaluating the way these scores are calculated in order to flatten out the curve.

Medical and clinical reasoning could potentially look like a discrete gaussian distribution. At least at first glance they seem roughly bell-curve shaped. Of course, discrete data cannot be normal.


```{r}
# Discretized data cannot be normally distributed, but we can still test for a different guide of normality

plot(ecdf(df$medical), main = "Empirical CDF", col = "blue")
plot(ecdf(df$clinical_reasoning), main = "Empirical CDF", col = "blue")
# Use a discrete normality test to see if the data is normally distributed


```



```{r}
# Run an ANOVA to see if there is a difference between hospital scores and non-hospital scores
hosp_df <- df[,c("UniqueID", "Hosp", "medical")]
hosp_df <- hosp_df %>% na.omit()

hosp_df$Hosp <- as.factor(hosp_df$Hosp)

anova <- aov(medical ~ Hosp, data = hosp_df)
summary(anova)

```
## Badging System

```{r}

# Make a badge score column for each of the core categories
# A score of 4 is worth one point, a score of 5 is worth two points


core_df$medical_points <- ifelse(core_df$medical == 4, 1, ifelse(core_df$medical == 5, 2, 0))
core_df$clinical_reasoning_points <- ifelse(core_df$clinical_reasoning == 4, 1, ifelse(core_df$clinical_reasoning == 5, 2, 0))
core_df$professionalism_points <- ifelse(core_df$professionalism == 4, 1, ifelse(core_df$professionalism == 5, 2, 0))
core_df$collaboration_points <- ifelse(core_df$collaboration == 4, 1, ifelse(core_df$collaboration == 5, 2, 0))

# First groupby uniqueID
# Track the number of points each student has overtime

new_df <- core_df %>% group_by(UniqueID) %>% mutate(medical_points = cumsum(medical_points), clinical_reasoning_points = cumsum(clinical_reasoning_points), professionalism_points = cumsum(professionalism_points), collaboration_points = cumsum(collaboration_points))

# For medical points, create a column called medical badges
# Once a student earns 5 medical points they get one badge, 10 is two badges, 16 is three badges

new_df$medical_badges <- ifelse(new_df$medical_points >= 16, 3, ifelse(new_df$medical_points >= 10, 2, ifelse(new_df$medical_points >= 5, 1, 0)))

# Same rules for clinical reasoning

new_df$clinical_reasoning_badges <- ifelse(new_df$clinical_reasoning_points >= 16, 3, ifelse(new_df$clinical_reasoning_points >= 10, 2, ifelse(new_df$clinical_reasoning_points >= 5, 1, 0)))



# Do the same for the other categories
new_df$professionalism_badges <- 
  ifelse(new_df$professionalism_points >= 23, 3, 
         ifelse(new_df$professionalism_points >= 17, 2, 
                ifelse(new_df$professionalism_points >= 8, 1, 0)))

new_df$collaboration_badges <- 
  ifelse(new_df$collaboration_points >= 23, 3, 
         ifelse(new_df$collaboration_points >= 17, 2, 
                ifelse(new_df$collaboration_points >= 8, 1, 0)))

grouped_df <- new_df %>% group_by(strBlock) %>% summarise(medical_badges = mean(medical_badges), clinical_reasoning_badges = mean(clinical_reasoning_badges), professionalism_badges = mean(professionalism_badges), collaboration_badges = mean(collaboration_badges))

# Plot the four columns over the strBlock category
grouped_df$strBlock <- factor(grouped_df$strBlock, levels = unique(grouped_df$strBlock))

grouped_df <- gather(grouped_df, key = "core_category", value = "points", -strBlock)

ggplot(grouped_df, aes(x = strBlock, y = points, color = core_category, group = core_category)) + 
  geom_line() + 
  geom_point() +  # Add points to ensure visibility
  ggtitle("Average Badges Over Time") + 
  xlab("Block") + 
  ylab("Average Badges") + 
  theme_minimal(base_size = 14) + 
  theme(legend.position = "top")





```

```{r}
# Now we can look at the distribution of badges for each of the core categories


max_badges <- new_df %>% group_by(UniqueID) %>% summarise(medical_badges = max(medical_badges), clinical_reasoning_badges = max(clinical_reasoning_badges), professionalism_badges = max(professionalism_badges), collaboration_badges = max(collaboration_badges))

# Histogram of this data

hist(max_badges$medical_badges, main = "Histogram of Medical Badges", xlab = "Medical Badges")

hist(max_badges$clinical_reasoning_badges, main = "Histogram of Clinical Reasoning Badges", xlab = "Clinical Reasoning Badges")

hist(max_badges$collaboration_badges, main = "Histogram of Collaboration Badges", xlab = "Collaboration Badges")

hist(max_badges$professionalism_badges, main = "Histogram of Professionalism Badges", xlab = "Professionalism Badges")


```



Replication Analysis: 
- Make the linear regression chart for each of the core four categories. Are there cases where the students are not improving over time?
- Making a time series chart for the student scores. 
- Take a linear regression of the core four categories to look at the percentage increase. 
- Do they come in with lower medical knowledge and show a higher increase in medical knowledge?
- Rerun the regressions as % change





