{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import msoffcrypto\n",
    "from io import BytesIO\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the password-protected Excel file\n",
    "file_path = \"data/FinalDataSet.xlsx\"\n",
    "\n",
    "load_dotenv()\n",
    "password = os.getenv(\"DATASET_PASSWORD\")\n",
    "\n",
    "# Decrypt the file\n",
    "with open(file_path, \"rb\") as f:\n",
    "    decrypted_file = BytesIO()\n",
    "    office_file = msoffcrypto.OfficeFile(f)\n",
    "    office_file.load_key(password=password)\n",
    "    office_file.decrypt(decrypted_file)\n",
    "\n",
    "# Load the decrypted file into pandas\n",
    "df = pd.read_excel(decrypted_file, engine=\"openpyxl\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "There appears to be lots of missing values in this dataset which we will need to appropriately handle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for na values \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Look at the Core 4 Attributes First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original df, but first let's analyze the first 7 columns only \n",
    "\n",
    "df_copy = df.iloc[:, :7].copy()\n",
    "# Now drop the 35 rows with missing values\n",
    "df_copy.dropna(inplace=True)\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is technically a time series\n",
    "# Group by uniqueID and then check out correlations?\n",
    "\n",
    "agg_corrs = df_copy.groupby(['UniqueID'])[['medical', 'clinical_reasoning', 'professionalism', 'collaboration']].corr()\n",
    "agg_corrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[['medical', 'clinical_reasoning', 'professionalism', 'collaboration']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Results:\n",
    "\n",
    "- It looks like the medical and clinical_reasoning attributes are correlated, while the professionalism and collaboration attributes are also correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the Data Normally Distributed?\n",
    "\n",
    "Well the data is discretely distributed, so obviously it can't be truly normal. But it still could be approximately normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's QQ plot the medical column\n",
    "columns = ['medical', 'clinical_reasoning', 'professionalism', 'collaboration']\n",
    "\n",
    "for c in columns:\n",
    "    stats.probplot(df_copy[c], dist=\"norm\", plot=plt)\n",
    "    plt.title(f\"QQ plot for {c}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov Test\n",
    "\n",
    "H0: The data is normally distributed. \n",
    "H1: The data takes some other distribution.\n",
    "\n",
    "Reject h0 in the case that p < 0.05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['medical', 'clinical_reasoning', 'professionalism', 'collaboration']\n",
    "for c in columns:\n",
    "    stat, p = stats.kstest(df_copy[c], 'norm', args=(np.mean(df_copy[c]), np.std(df_copy[c])))\n",
    "    print(f\"KS Test for {c}: {stat}, {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the data is not normally distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot student scores over time for each category\n",
    "\n",
    "df_copy.groupby('UniqueID')[['medical', 'clinical_reasoning', 'professionalism', 'collaboration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.groupby('UniqueID')[\"medical\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_order = []\n",
    "\n",
    "for l in ['A', 'B', 'C', 'D']:\n",
    "    if l == 'A':\n",
    "        for i in range(1, 8):\n",
    "            block_order.append(f\"{l}{i}\")\n",
    "    else:\n",
    "        for i in range(1, 7):\n",
    "            block_order.append(f\"{l}{i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_scores(df, student_id):\n",
    "    return df[df['UniqueID'] == student_id][['medical', 'clinical_reasoning', 'professionalism', 'collaboration']].values\n",
    "\n",
    "def get_student_block_order(df, student_id):\n",
    "    return df[df['UniqueID'] == student_id]['strBlock'].values\n",
    "\n",
    "def plot_student_scores(df, student_id):\n",
    "    scores = get_student_scores(df, student_id)\n",
    "    block_order = get_student_block_order(df, student_id)\n",
    "    \n",
    "    # Add jitter to scores\n",
    "    jitter = np.random.uniform(-0.1, 0.1, scores.shape)\n",
    "    scores_jittered = scores + jitter\n",
    "\n",
    "    plt.plot(scores_jittered, marker='o', alpha=0.5)\n",
    "    plt.xticks(range(len(block_order)), block_order)\n",
    "    plt.title(f\"Scores for student {student_id}\")\n",
    "    plt.legend(['medical', 'clinical_reasoning', 'professionalism', 'collaboration'])\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_student_scores(df_copy, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggregate_scores(df):\n",
    "    # Compute mean scores for each StrBlock\n",
    "    summary = df.groupby('strBlock', observed = True)[['medical', 'clinical_reasoning', 'professionalism', 'collaboration']].mean()\n",
    "    summary.plot(marker='o')\n",
    "    plt.title('Average Scores Across Students')\n",
    "    plt.ylabel('Average Score')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "plot_aggregate_scores(df_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Services\n",
    "\n",
    "Do certain services (classes) perform better during certain blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'service' and 'StrBlock' and calculate the mean medical score\n",
    "\n",
    "columns = ['medical', 'clinical_reasoning', 'professionalism', 'collaboration']\n",
    "\n",
    "tracker = []\n",
    "\n",
    "for c in columns:\n",
    "    \n",
    "\n",
    "    grouped = df_copy.groupby(['service', 'strBlock'])[c].mean()\n",
    "\n",
    "    # Reset index to make the grouped data easier to work with\n",
    "    grouped_reset = grouped.reset_index()\n",
    "\n",
    "    # Find the StrBlock with the maximum medical score for each service\n",
    "    max_blocks = grouped_reset.loc[grouped_reset.groupby('service')[c].idxmax()]\n",
    "\n",
    "    # Display the result\n",
    "    tracker.append(max_blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes together on 'service'\n",
    "\n",
    "\n",
    "# Example DataFrames for different categories\n",
    "max_blocks_medical = tracker[0].rename(columns={'strBlock': 'max_block_medical', 'medical': 'max_avg_medical'})\n",
    "max_blocks_clinical = tracker[1].rename(columns={'strBlock': 'max_block_clinical', 'medical': 'max_avg_clinical'})\n",
    "max_blocks_professionalism = tracker[2].rename(columns={'strBlock': 'max_block_professionalism', 'medical': 'max_avg_professionalism'})\n",
    "max_blocks_collaboration = tracker[3].rename(columns={'strBlock': 'max_block_collaboration', 'medical': 'max_avg_collaboration'})\n",
    "\n",
    "# Start with one DataFrame and merge the others iteratively\n",
    "merged_df = max_blocks_medical.merge(\n",
    "    max_blocks_clinical, on='service', how='outer'\n",
    ").merge(\n",
    "    max_blocks_professionalism, on='service', how='outer'\n",
    ").merge(\n",
    "    max_blocks_collaboration, on='service', how='outer'\n",
    ")\n",
    "\n",
    "# Count the number of blocks shared in each row\n",
    "block_columns = ['max_block_medical', 'max_block_clinical', 'max_block_professionalism', 'max_block_collaboration']\n",
    "\n",
    "# Add a new column counting the number of shared blocks\n",
    "merged_df['shared_blocks_count'] = merged_df[block_columns].apply(lambda row: row.nunique(), axis=1)\n",
    "\n",
    "# Convert the unique count to a count of shared blocks (total columns - unique values)\n",
    "merged_df['shared_blocks_count'] = len(block_columns) - merged_df['shared_blocks_count']\n",
    "\n",
    "merged_df.sort_values('shared_blocks_count', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_labels = {\n",
    "    5600 : 'VTMED 5600: Ambulatory and Production Medicine',\n",
    "    5601: 'VTMED 5601: Community Practice Service:',\n",
    "    5602: 'VTMED 5602: Small Animal Medicine',\n",
    "    5603: 'VTMED 5603: Small Animal Surgery',\n",
    "    5604: 'VTMED 5604:Large Animal Medicine',\n",
    "    5605: 'VTMED 5605: Large Animal Surgery',\n",
    "    5606: 'VTMED 5606: Anesthesia',\n",
    "    5607: 'VTMED 5607: Dermatology',\n",
    "    5608: 'VTMED 5608: Opthalmology',\n",
    "    5609: 'VTMED 5609: Anatomic Pathology',\n",
    "    5610: 'VTMED 5610: Imaging',\n",
    "    5611: 'VTMED 5611: Small Animal Emergency and Critical Care',\n",
    "    5613: 'VTMED 5613: Small Animal Orthopedics',\n",
    "    6600: 'VTMED 6600: Theriogenology',\n",
    "    6601: 'VTMED 6601: Cardiology',\n",
    "    6602: 'VTMED 6602: Lab Animal Medicine',\n",
    "    6603: 'VTMED 6603: Clinical Wildlife, Exotic, and Zoo Animal Medicine',\n",
    "    6608: 'VTMED 6608: Clinical Oncology',\n",
    "    6614: 'VTMED 6614: Large Animal Emergency and Critical Care',\n",
    "    6616: 'VTMED 6616: Small Animal Dentistry',\n",
    "    6618: 'VTMED 6618: Clinical Neurology',\n",
    "    6619: 'VTMED 6619: Clinical Pathology',\n",
    "    6623: 'VTMED 6623: Clinical Rotation in Shelter Medicine',\n",
    "    6624: 'VTMED 6624: Primary Care Surgery',\n",
    "    6627: 'VTMED 6627: Farrier',\n",
    "    6628: 'VTMED 6628: Clinical Sports Medicine and Rehabilitation',\n",
    "    6629: 'VTMED 6629: Wildlife Medicine'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
